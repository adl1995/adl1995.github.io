<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>/home/adeel - Security</title><link href="/" rel="alternate"></link><link href="/feeds/security.atom.xml" rel="self"></link><id>/</id><updated>2023-05-29T18:00:00+02:00</updated><entry><title>Rate limiting in HAProxy and Nginx</title><link href="/rate-limiting-in-haproxy-and-nginx.html" rel="alternate"></link><published>2023-05-29T18:00:00+02:00</published><updated>2023-05-29T18:00:00+02:00</updated><author><name>Adeel Ahmad</name></author><id>tag:None,2023-05-29:/rate-limiting-in-haproxy-and-nginx.html</id><summary type="html">&lt;p&gt;Rate-limiting is a common strategy for safe guarding a server from potential DDoS attacks or sudden peaks in network traffic. Rate-limiting instructs the server to block requests from certain IP addresses that are sending an unusual number of requests to the system.&lt;/p&gt;
&lt;p&gt;We can apply rate-limiting to both Nginx and HAProxy. Nginx runs on each end node hosting the service, while HAProxy serves as the load-balancer and distributes incoming requests among available nodes. This post describes how to rate-limit requests on both Nginx and HAProxy and shows how to whitelist IPs and rate-limit a single URL. The final section shows how to apply this configuration in Puppet.&lt;/p&gt;
&lt;h2&gt;1. Rate-limiting in HAProxy&lt;/h2&gt;
&lt;p&gt;This section describes how to configure HAProxy to rate-limit â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Rate-limiting is a common strategy for safe guarding a server from potential DDoS attacks or sudden peaks in network traffic. Rate-limiting instructs the server to block requests from certain IP addresses that are sending an unusual number of requests to the system.&lt;/p&gt;
&lt;p&gt;We can apply rate-limiting to both Nginx and HAProxy. Nginx runs on each end node hosting the service, while HAProxy serves as the load-balancer and distributes incoming requests among available nodes. This post describes how to rate-limit requests on both Nginx and HAProxy and shows how to whitelist IPs and rate-limit a single URL. The final section shows how to apply this configuration in Puppet.&lt;/p&gt;
&lt;h2&gt;1. Rate-limiting in HAProxy&lt;/h2&gt;
&lt;p&gt;This section describes how to configure HAProxy to rate-limit incoming requests and block requests that cross a certain threshold. HAProxy provides rate-limiting in the following contexts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rate queuing:&lt;/strong&gt; The simplest form of rate-limiting in which requests are queued if they cross a certain threshold. Subsequent requests are served in FIFO order.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sliding window:&lt;/strong&gt; Requests are stored in a &lt;em&gt;stick table&lt;/em&gt; that keeps a record of incoming IP addresses. A threshold is defined, allowing the user to make a certain number of requests in a given time period. Subsequent requests are denied with a &lt;code&gt;429&lt;/code&gt; status code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fixed window:&lt;/strong&gt; Similar to the sliding window, we define an interval as before; however, instead of storing the request rate, we keep a request counter. When requests for a certain user reach their limit, subsequent requests get blocked, usually for a period of 24 hours (can be modified). This is mainly used for APIs where user requests are limited to, for example, 1000 per day.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1.1. HAProxy configuration&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This &lt;a href="https://www.haproxy.com/blog/four-examples-of-haproxy-rate-limiting"&gt;HAProxy blog&lt;/a&gt; covers the basics of applying rate-limiting on the server side.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HAProxy configuration is divided into four sections: &lt;code&gt;frontend&lt;/code&gt;, &lt;code&gt;backend&lt;/code&gt;, &lt;code&gt;defaults&lt;/code&gt;, and &lt;code&gt;global&lt;/code&gt;. The &lt;code&gt;frontend&lt;/code&gt; handles incoming requests from clients, and the &lt;code&gt;backend&lt;/code&gt; is expected to fulfill the request. Note that all these steps can be performed in a combined config section, but for maintainability and readability, it is divided into separate sections.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;frontend&lt;/code&gt;: Handles all incoming requests from clients.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Expected to fulfill the request.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;defaults&lt;/code&gt;: Contains default settings for the server. Can be used to avoid duplication.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;global&lt;/code&gt;: Global settings for the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;To rate-limit in HAProxy, we first need to decrypt the HTTPS traffic using SSL offloading. This feature is only available in HAProxy versions 1.x and onwards.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We will only focus on the &lt;code&gt;frontend&lt;/code&gt; and &lt;code&gt;backend&lt;/code&gt; configuration sections, as the other sections contain default configuration and will not be used for setting up load balancing.&lt;/p&gt;
&lt;h3&gt;1.2. Defining the frontend configuration&lt;/h3&gt;
&lt;p&gt;In the &lt;code&gt;frontend&lt;/code&gt; section, we specify the port and IP address where our site listens for traffic. If we have configured SSL for our site, we also need to specify the location of the certificate file.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;View the &lt;code&gt;haproxy&lt;/code&gt; systemd service (&lt;code&gt;$ systemctl status haproxy&lt;/code&gt;) to check where the configuration file is defined.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;frontend my_example_site.com&lt;/span&gt; &lt;span class="c1"&gt;# The keyword following &amp;#39;frontend&amp;#39; is the label.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;bind *:443 ssl crt /etc/ssl/cert1.pem&lt;/span&gt;  
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;bind *:80&lt;/span&gt; &lt;span class="c1"&gt;# Bind all IP addresses to listen on port 80.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;default_backend example_site_backend&lt;/span&gt; &lt;span class="c1"&gt;# Afterwards, traffic will get redirected to this backend.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;http-request track-sc0 src&lt;/span&gt; &lt;span class="c1"&gt;# (Described in section 1.4. Stick tables).&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;http-request deny deny_status 429 if { sc_http_req_rate(0) gt 50 } !white_list&lt;/span&gt; &lt;span class="c1"&gt;# (Described in section 1.5. Setting the Request Rate Limit).&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;mode http&lt;/span&gt; &lt;span class="c1"&gt;# HTTP mode instructs the server to inspect the traffic before passing it to the backend.&lt;/span&gt;
&lt;span class="c1"&gt;# Other options include &amp;#39;tcp,&amp;#39; which means the traffic is encrypted and will be passed on to the backend as is.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;redirect scheme https code 301 if !{ ssl_fc }&lt;/span&gt; &lt;span class="c1"&gt;# Instructs the server to redirect traffic to HTTPS with a 301 status code if they try accessing from an unencrypted site.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick-table type ipv6 size 100k expire 30s store http_req_rate(1s)&lt;/span&gt; &lt;span class="c1"&gt;# See the section below for stick tables.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;1.3. Defining the backend configuration&lt;/h3&gt;
&lt;p&gt;The backend section defines a pool of servers where requests are actually handled. Below is an example backend configuration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;backend my_example_site.com_backend&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;balance roundrobin&lt;/span&gt; &lt;span class="c1"&gt;# Select the load balancing algorithm.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;default-server inter 2s fall 2 rise 2&lt;/span&gt; &lt;span class="c1"&gt;# See below:&lt;/span&gt;
&lt;span class="c1"&gt;# inter: Specifies the inter-check delay for health checks. In this case, &amp;#39;inter 2s&amp;#39; indicates that the interval between two consecutive health checks for a server is 2 seconds.&lt;/span&gt;
&lt;span class="c1"&gt;# fall: Specifies the number of consecutive failed health checks after which a server is considered down. With &amp;#39;fall 2&amp;#39;, if two consecutive health checks fail, the server will be marked as down.&lt;/span&gt;
&lt;span class="c1"&gt;# rise: Specifies the number of consecutive successful health checks required for a server to be marked as up. With &amp;#39;rise 2&amp;#39;, after two consecutive successful health checks, the server will be marked as up.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;mode http&lt;/span&gt; &lt;span class="c1"&gt;# Instruct backend servers to communicate using the HTTP protocol.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;option httpchk HEAD /status HTTP/1.1\r\nHost:\ www.example.com&lt;/span&gt; &lt;span class="c1"&gt;# See below:&lt;/span&gt;
&lt;span class="c1"&gt;# Sends a HEAD request to the /status path of the backend servers, specifying the Host header as www.example.com, to perform health checks and determine the availability and health status of the servers.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick on src&lt;/span&gt; &lt;span class="c1"&gt;# Enable session stickiness based on the source IP address of the client.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick-table type ip size 20k peers sct_my_example_site&lt;/span&gt; &lt;span class="c1"&gt;# Define a stick table.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;server server1 192.168.1.25:80&lt;/span&gt; &lt;span class="c1"&gt;# Define a list of servers; each on a separate line.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;1.4. Stick tables&lt;/h3&gt;
&lt;p&gt;Stick tables are what make it possible to rate-limit servers. They are a key-value store that holds an incoming IP address as the key with its counter. The counter is incremented whenever a new request is made to the server. Using this information, we can define rules to block requests if they cross a certain threshold.&lt;/p&gt;
&lt;p&gt;We can tweak how long a stick table can hold information before erasing its buffer. A stick table can be defined as follows.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;backend st_src_global&lt;/span&gt; &lt;span class="c1"&gt;# The backend for which we are defining this.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick-table type ip size 1m expire 10s store http_req_rate(10s)&lt;/span&gt; &lt;span class="c1"&gt;# A stick table that can hold 1m&lt;/span&gt;
&lt;span class="c1"&gt;# (1048576) IPs and expires after 10 seconds unless it is accessed during that time.&lt;/span&gt;
&lt;span class="c1"&gt;# The HTTP request rate is calculated in an interval of 10 seconds.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;HAProxy provides up to 12 stick table counter tracks, labeled from &lt;code&gt;sc0&lt;/code&gt; up to &lt;code&gt;sc11&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;1.5. Setting the request rate limit&lt;/h3&gt;
&lt;p&gt;We can use the HAProxy built-in &lt;code&gt;http_req_rate&lt;/code&gt; directive to measure the request rate. In this example, we will return a &lt;code&gt;429&lt;/code&gt; if a user makes more than 50 requests in an interval of 5 seconds.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick-table type ip size 1m expire 5s store http_req_rate(5s)&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;http-request deny deny_status 429 if { sc_http_req_rate(0) gt 50 } !white_list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;The parameter &lt;code&gt;0&lt;/code&gt; for &lt;code&gt;sc_http_req_rate&lt;/code&gt; refers to the stick counter number.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;1.6. Whitelisting an IP address&lt;/h3&gt;
&lt;p&gt;To define a whitelist, we use Access Control Lists (ACLs). In HAProxy, they allow us to test various conditions and perform a given action based on those tests. They can be defined as follows.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;acl white_list src 192.168.1.1 ...&lt;/span&gt; &lt;span class="c1"&gt;# List of IP addresses to whitelist.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;http-request track-sc0 src&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;http-request deny deny_status 429 if { sc_http_req_rate(0) gt 25 } !white_list&lt;/span&gt; &lt;span class="c1"&gt;# This applies to all incoming IPs, except for those defined in the whitelist.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;1.7. Limiting the number of open connections&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;conn_cur&lt;/code&gt; option can be used to count the number of open connections from an IP address. If a user has too many connections open, we can deny their further connections. The syntax remains similar as before.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stick-table type ip size 1m expire 10s store conn_cur&lt;/span&gt; &lt;span class="c1"&gt;# Define a stick table.&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tcp-request content track-sc0 src&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tcp-request content reject if { sc_conn_cur(0) gt 10 }&lt;/span&gt; &lt;span class="c1"&gt;# The parameter `0` in sc_conn_cur refers to the stick counter number.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;By using &lt;code&gt;tcp-request&lt;/code&gt; instead of &lt;code&gt;http-request&lt;/code&gt;, we do not evaluate HTTP headers in the packet, making the processing more efficient.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HAProxy provides additional counters for measuring the error rate of a site (HTTP requests that have a &lt;code&gt;4xx&lt;/code&gt; status code). The &lt;code&gt;bytes_out_rate&lt;/code&gt; counter can be used to track content that is generating the most traffic for your site. It is also possible to create custom statistics using the general-purpose counter &lt;code&gt;sc_inc_gpc0&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;HAProxy Enterprise has features that allow individual increments across all peer nodes. This approach is better for detecting DDoS attacks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;2. Rate-limiting in Nginx&lt;/h2&gt;
&lt;p&gt;Nginx supports various rate-limiting schemes. In the example below, we'll set up two-stage rate-limiting.&lt;/p&gt;
&lt;p&gt;Two-stage rate-limiting throttles a request before blocking it. To implement this, we first define the &lt;code&gt;limit_req_zone&lt;/code&gt; in the Nginx configuration file &lt;code&gt;nginx.conf&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;limit_req_zone zone=two_stage_limit_store:10m rate=5r/s;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To limit certain types of requests, we can use the &lt;code&gt;$limit&lt;/code&gt; variable. This can be used for rate-limiting a specific request method. For example, to rate-limit POST calls, we can write:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;map $request_method $limit {&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;default         &amp;#39;&amp;#39;;&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;POST            &amp;lt;IP of your server&amp;gt;;&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;}&lt;/span&gt;

&lt;span class="l l-Scalar l-Scalar-Plain"&gt;limit_req_zone $limit zone=two_stage_limit_store:10m rate=5r/s;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, we reference the above limit in our server configuration. If the server hostname is "example.com," this file will be located at &lt;code&gt;/etc/nginx/sites-enabled/example.com.conf&lt;/code&gt;. We first specify the response code for requests exceeding our rate-limit in the &lt;code&gt;server&lt;/code&gt; section.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;server {&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;...&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;limit_req_status 429;&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;...&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;The error code &lt;code&gt;429&lt;/code&gt; corresponds to "Too Many Requests."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Next, we define the &lt;code&gt;location&lt;/code&gt;(s) we would like to rate-limit (within the &lt;code&gt;server&lt;/code&gt; section). To rate-limit a specific endpoint, we can add:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;location /token/abc {&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;limit_req zone=two_stage_limit_store burst=25 delay=20;&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;...&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: If we replace &lt;code&gt;/token/abc&lt;/code&gt; with &lt;code&gt;/&lt;/code&gt;, we will rate-limit all endpoints on our server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here, we reference the limit zone defined earlier in the &lt;code&gt;nginx.conf&lt;/code&gt; file. The next two parameters are our rate-limit parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;burst&lt;/code&gt; specifies the number of requests to allow within 1 second.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delay&lt;/code&gt; indicates the request count after which subsequent requests are throttled.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To summarize, in the above config, we allow up to 25 requests per second. Requests 1 to 20 will reach the server without any delay. Requests 21 to 25 will be throttled, and any subsequent requests will be rejected with a &lt;code&gt;429&lt;/code&gt; status code.&lt;/p&gt;
&lt;p&gt;Upon reviewing the text, I have identified a few minor typos and suggestions for improvement:&lt;/p&gt;
&lt;h2&gt;3. Configuration in Puppet&lt;/h2&gt;
&lt;p&gt;The configurations below are an exact replica of what is shown above, but in Puppet. It is assumed that the required services are already installed on the system.&lt;/p&gt;
&lt;h3&gt;3.1. HAProxy configuration&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# HAProxy Configuration&lt;/span&gt;

&lt;span class="l l-Scalar l-Scalar-Plain"&gt;$ipv4s_list = ...&lt;/span&gt; &lt;span class="c1"&gt;# List of IPs.&lt;/span&gt;

&lt;span class="l l-Scalar l-Scalar-Plain"&gt;haproxy::frontend { &amp;quot;my_example_site.com&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;bind    =&amp;gt; {&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;*:80&amp;#39;   =&amp;gt; [],&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;:::80&amp;#39;  =&amp;gt; [],&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;# SSL termination for rate-limiting.&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;*:443&amp;#39;  =&amp;gt; &amp;quot;ssl crt ${certificate_path}&amp;quot;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;:::443&amp;#39; =&amp;gt; &amp;quot;ssl crt ${certificate_path}&amp;quot;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;},&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;options =&amp;gt; {&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;mode&amp;#39;            =&amp;gt; &amp;#39;http&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;redirect&amp;#39;        =&amp;gt; &amp;#39;scheme https code 301 if !{ ssl_fc }&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;stick-table&amp;#39;     =&amp;gt; &amp;#39;type ipv6 size 100k expire 30s store http_req_rate(1s)&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;acl&amp;#39;             =&amp;gt; &amp;quot;white_list src ${join($ipv4s_list, &amp;#39; &amp;#39;)}&amp;quot;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;http-request&amp;#39;    =&amp;gt; [&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;track-sc0 src&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;# This setting allows 45 requests per second.&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;deny deny_status 429 if { sc_http_req_rate(0) gt 45 } !white_list&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;],&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;default_backend&amp;#39; =&amp;gt; &amp;quot;my_example_site.com_backend&amp;quot;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;},&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;

&lt;span class="l l-Scalar l-Scalar-Plain"&gt;haproxy::backend { &amp;quot;my_example_site.com_backend&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;options          =&amp;gt; {&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;balance&amp;#39;        =&amp;gt; &amp;#39;roundrobin&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;mode&amp;#39;           =&amp;gt; &amp;#39;http&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;default-server&amp;#39; =&amp;gt; &amp;#39;inter 2s fall 2 rise 2&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;option&amp;#39;         =&amp;gt; [&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;quot;httpchk HEAD /status HTTP/1.1\r\nHost:\ www.example.com&amp;quot;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;],&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;stick&amp;#39;          =&amp;gt; &amp;#39;on src&amp;#39;,&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;stick-table&amp;#39;    =&amp;gt; &amp;quot;type ip size 20k peers sct_my_example_site&amp;quot;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;},&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;3.2. Nginx configuration&lt;/h3&gt;
&lt;p&gt;Similarly, for Nginx, we define the same configuration as above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Two-stage rate limiting for all nodes, see: https://www.nginx.com/blog/rate-limiting-nginx/#Two-Stage-Rate-Limiting&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;nginx::resource::location { &amp;#39;rate limit&amp;#39;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ensure                =&amp;gt; present,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ssl                   =&amp;gt; true,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ssl_only              =&amp;gt; true,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;location              =&amp;gt; &amp;#39;/&amp;#39;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;server                =&amp;gt; $facts[&amp;#39;networking&amp;#39;][&amp;#39;fqdn&amp;#39;],&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;limit_zone            =&amp;gt; &amp;#39;two_stage_limit_store burst=25 delay=20&amp;#39;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;proxy                 =&amp;gt; &amp;quot;http://my_example_site.com:8080&amp;quot;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;proxy_read_timeout    =&amp;gt; &amp;#39;90s&amp;#39;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;proxy_connect_timeout =&amp;gt; &amp;#39;90s&amp;#39;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;proxy_send_timeout    =&amp;gt; &amp;#39;90s&amp;#39;,&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;proxy_set_header      =&amp;gt; $proxy_set_header,&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;

&lt;span class="l l-Scalar l-Scalar-Plain"&gt;class { &amp;#39;nginx&amp;#39;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Override the default Nginx log format.&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;log_format              =&amp;gt;&lt;/span&gt;
    &lt;span class="l l-Scalar l-Scalar-Plain"&gt;{&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;json_combined&amp;#39; =&amp;gt; &amp;#39;escape=json&amp;#39;&lt;/span&gt;
        &lt;span class="l l-Scalar l-Scalar-Plain"&gt;&amp;#39;{&amp;quot;data&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p p-Indicator"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;time_local&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${time_local}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;remote_addr&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${remote_addr}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;remote_user&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${remote_user}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;request&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${request}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;status&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;${status}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;body_bytes_sent&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${body_bytes_sent}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;request_time&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${request_time}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;http_referrer&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${http_referer}&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;&amp;quot;http_user_agent&amp;quot;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${http_user_agent}&amp;quot;&amp;#39;&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p p-Indicator"&gt;}&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&lt;/span&gt;
    &lt;span class="s"&gt;},&lt;/span&gt;
    &lt;span class="s"&gt;limit_req_zone&lt;/span&gt;&lt;span class="nv"&gt;          &lt;/span&gt;&lt;span class="s"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${facts[&amp;#39;&lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;networking&amp;#39;][&amp;#39;ip&amp;#39;]} zone=two_stage_limit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.haproxy.com/blog/haproxy-ssl-termination/"&gt;https://www.haproxy.com/blog/haproxy-ssl-termination/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.haproxy.com/blog/introduction-to-haproxy-stick-tables/"&gt;https://www.haproxy.com/blog/introduction-to-haproxy-stick-tables/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.haproxy.com/blog/four-examples-of-haproxy-rate-limiting/"&gt;https://www.haproxy.com/blog/four-examples-of-haproxy-rate-limiting/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.haproxy.com/blog/introduction-to-haproxy-acls/"&gt;https://www.haproxy.com/blog/introduction-to-haproxy-acls/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://uldissturms.github.io/2014/03/03/request-rate-limiting-with-haproxy-vs-nginx-using-chef-solo/"&gt;http://uldissturms.github.io/2014/03/03/request-rate-limiting-with-haproxy-vs-nginx-using-chef-solo/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sysbee.net/blog/sysbee-blog/haproxy-sysadmins-swiss-army-knife/"&gt;https://www.sysbee.net/blog/sysbee-blog/haproxy-sysadmins-swiss-army-knife/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Security"></category></entry><entry><title>The Kerberos Authentication System for Single Sign-On (SSO)</title><link href="/the-kerberos-authentication-system-for-single-sign-on-sso.html" rel="alternate"></link><published>2019-07-21T21:43:00+02:00</published><updated>2019-07-21T21:43:00+02:00</updated><author><name>Adeel Ahmad</name></author><id>tag:None,2019-07-21:/the-kerberos-authentication-system-for-single-sign-on-sso.html</id><summary type="html">&lt;p&gt;When working with authentication protocols the commonly used technique in the past was known as &lt;em&gt;authentication by assertion&lt;/em&gt;. In this scheme a user logs in to their machine which then authenticates their request to a remote server. Once the authentication is finished the user can then communicate with other services. This provides a very low level of security, which has led to numerous vulnerabilities in the early versions of the &lt;a href="https://en.wikipedia.org/wiki/Berkeley_r-commands#Security"&gt;rlogin&lt;/a&gt; Unix login utility.&lt;/p&gt;
&lt;p&gt;An alternative solution is for the user to repeatedly provide their password each time they wish to use a service. This however requires the user to send their plain text password over the network, which could potentially be intercepted by a third-party user and can get â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working with authentication protocols the commonly used technique in the past was known as &lt;em&gt;authentication by assertion&lt;/em&gt;. In this scheme a user logs in to their machine which then authenticates their request to a remote server. Once the authentication is finished the user can then communicate with other services. This provides a very low level of security, which has led to numerous vulnerabilities in the early versions of the &lt;a href="https://en.wikipedia.org/wiki/Berkeley_r-commands#Security"&gt;rlogin&lt;/a&gt; Unix login utility.&lt;/p&gt;
&lt;p&gt;An alternative solution is for the user to repeatedly provide their password each time they wish to use a service. This however requires the user to send their plain text password over the network, which could potentially be intercepted by a third-party user and can get compromised.&lt;/p&gt;
&lt;p&gt;Kerberos aims to solve this issue by introducing a mechanism where a user only logs-in to their local machine once, also known as Single-Sign On or SSO. The user's information is transferred securely over the network (and is deprived of plaintext passwords). This removes the risk of user's password being sniffed by an eavesdropper as the protocol only uses secret keys for communicating with the outside service.&lt;/p&gt;
&lt;h3&gt;The Kerberos Authentication System&lt;/h3&gt;
&lt;p&gt;The Kerberos Authentication System was first introduced in 1988 (&lt;a href="https://www3.nd.edu/~dthain/courses/cse66771/summer2014/papers/kerberos.pdf"&gt;paper&lt;/a&gt;). Its motivation was to authenticate a client to a server without sharing the user's password across a network. Normal authentication protocols are prone to outside attackers who can sniff the network traffic and potentially gain access to user credentials.&lt;/p&gt;
&lt;p&gt;This led Kerberos to gain popularity during the past few decades and it is now being used in various organisations as their main authentication system, including &lt;a href="http://information-technology.web.cern.ch/services/fe/afs/howto/authenticate-processes"&gt;CERN&lt;/a&gt;. Kerberos is also the default authentication system used by the Windows Operating System.&lt;/p&gt;
&lt;p&gt;Before explaining how this protocol works, let's review the terminology used in Kerberos. In Kerberos the client and user are referred to as a "process" and a "principal", respectively. Apart from this it also has a naming convention for the entity used for authentication, which consists of its primary name, the instance, and a realm, and is expressed as &lt;code&gt;name.instance@realm&lt;/code&gt;. The primary name is the name of the user, and the instance allows the system to distinguish variations among the primary name. A realm refers to the administrative entity, for example, &lt;code&gt;CERN.CH&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Kerberos exchanges a series of encrypted messages with the verifier (server) to prove that the process is running on behalf of the intended user. These messages include an encryption key, which is unique to each user, and is derived from their password. When an application communicates with the server it encrypts the data using this key and the server verifies its confidentiality through its checksum.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Although Kerberos ensures that the user's password is not shared with the service, there is still a risk of the user's machine being compromised, for example, through a Trojan horse malware.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Obtaining the encryption key&lt;/h3&gt;
&lt;p&gt;Before a client sends an authentication request to the server, the authentication key is only known by the server, which it regenerates each time the client tries to authenticate itself. Kerberos then issues a certificate which is encrypted with the newly generated key and distributes it to the client. This certificate includes, among other information, a session key along with its TTL timestamp (after which the key will expire).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The encryption algorithm used by Kerberos is called DES or &lt;a href="https://en.wikipedia.org/wiki/Data_Encryption_Standard"&gt;Data Encryption Scheme&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;The Kerberos Database Management Service (KDMS)&lt;/h3&gt;
&lt;p&gt;The KDMS is responsible for performing write operations to the Kerberos database. The current version of Kerberos states that the management service should only run on the server node, as shown in the figure below.&lt;/p&gt;
&lt;figure style="text-align:center;" class="image"&gt;
  &lt;img src="/images/kerberos/kdms.png" alt="kdms"&gt;
  &lt;figcaption&gt;KDMS&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;KDMS utilities&lt;/h4&gt;
&lt;p&gt;The client side of Kerberos provides two utilities for communicating with the server. The first utility, &lt;code&gt;kpasswd&lt;/code&gt;, allows the principal to update their password. The second utility, &lt;code&gt;kadmin&lt;/code&gt;, allows the administrator to access the Kerberos database. It provides numerous commands for modifying, updating, and deleting a principal. As an example, the password for the principal user can be updated by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ kpasswd adeel
Password for adeel@CERN.CH: &amp;lt;current password&amp;gt;
Enter new password: &amp;lt;new password&amp;gt;
Enter it again: &amp;lt;new password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: It is not necessary to specify the username in the above command if that user is only registered with a single realm.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;An important point to note here is that KDMS does not rely on the standard ticket-granting service, but rather requires the principal (user) to use the authentication service each time they interact with the database. Because of this feature, a logged-in user is not at risk of getting their password modified by a malicious user if their workstation is left unattended.&lt;/p&gt;
&lt;figure style="text-align:center;" class="image"&gt;
  &lt;img src="/images/kerberos/kpasswd-kadmin-auth.png" alt="kpasswd-kadmin-auth"&gt;
  &lt;figcaption&gt;Authentication process for kpasswd and kadmin&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;Kerberos database replication&lt;/h4&gt;
&lt;p&gt;To achieve better performance and high availability, Kerberos clients posses an exact replica of the Kerberos server database. The database needs to be in sync with the server and must contain the latest changes. For this, Kerberos provides two tools called &lt;code&gt;kprop&lt;/code&gt; and &lt;code&gt;kpropd&lt;/code&gt;. The &lt;code&gt;kprop&lt;/code&gt; tool runs on the server side and periodically creates a dump of the database (every 1 hour by default)  and sends it to the client.&lt;/p&gt;
&lt;figure style="text-align:center;" class="image"&gt;
  &lt;img src="/images/kerberos/database-replication.png" alt="database-replication"&gt;
  &lt;figcaption&gt;Database replication in Kerberos&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Some additional steps are not mentioned here for brevity. These include the database checksum, which is used for verifying the data authenticity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Kerberos in practice&lt;/h3&gt;
&lt;p&gt;In some implementations of Kerberos the ticket is obtained as part of the system login process. Thus the user is often oblivious that Kerberos is running in the background.&lt;/p&gt;
&lt;p&gt;In other cases the user can manually login using the &lt;code&gt;kinit&lt;/code&gt; tool:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ kinit adeel
Password for adeel@CERN.CH: &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Limitations of Kerberos&lt;/h3&gt;
&lt;p&gt;Although Kerberos takes away much of the hassle involved in the authentication process, it nevertheless has some limitations entailed with it. Firstly, if the user has chosen a weak password, it is relatively easy for an attacker to impersonate themselves as the real user. Secondly, the ticket expiration time is always a trade-off between security and convenience. A longer expiration time raises the risk of the session key being stolen and thus allowing an attacker to gain authority over the services, and a short expiration time requires the user to regularly re-enter their plaintext password into the shell, which could be infected by a malware.&lt;/p&gt;
&lt;p&gt;Kerberos also does not support multifactor authentication by default, which is nowadays becoming the norm for most modern-day applications.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Disclaimer: The images in this blog post are taken from the &lt;a href="https://www3.nd.edu/~dthain/courses/cse66771/summer2014/papers/kerberos.pdf"&gt;Kerberos MIT paper&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="Security"></category></entry></feed>